{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating CNN Performance on RRAM-based In-Memory Computing Accelerators\n",
    "\n",
    "In this notebook, you will use the [cross-sim](https://github.com/sandialabs/cross-sim) simulator to analyze how the performance of a Convolutional Neural Network (CNN) for MNIST digit recognition is affected when deployed on RRAM-based In-Memory-Computing (IMC) accelerators.\n",
    "\n",
    "You will:\n",
    "- Train and evaluate a CNN in standard PyTorch (software-only baseline).\n",
    "- Evaluate the same trained network using cross-sim to simulate RRAM hardware effects.\n",
    "- Retrain the network using Hardware-Aware Training (HAT) with cross-sim, then evaluate its performance on simulated hardware.\n",
    "\n",
    "Finally, you can draw your own digit and see how each network performs on your input!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipycanvas import Canvas\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "# from cross_sim import CrossSimModel, CrossSimConfig\n",
    "from simulator import AnalogCore\n",
    "from simulator import CrossSimParameters\n",
    "from applications.mvm_params import set_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "We will use the MNIST dataset. Let's load and preprocess it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./MNIST', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./MNIST', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the CNN Model\n",
    "\n",
    "We will use a simple CNN suitable for MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluation Functions\n",
    "\n",
    "Let's define helper functions for training and evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, trainloader, optimizer, criterion, epochs=1):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in trainloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def test(model, device, testloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "    return 100. * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Case I: PyTorch Training and Inference\n",
    "\n",
    "Train and evaluate the CNN using only PyTorch (software baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_pt = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model_pt.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(model_pt, device, trainloader, optimizer, criterion, epochs=2)\n",
    "acc_pt = test(model_pt, device, testloader)\n",
    "print(f'PyTorch (SW) Test Accuracy: {acc_pt:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Case II: PyTorch Training, CrossSim Inference\n",
    "\n",
    "Evaluate the PyTorch-trained model using cross-sim to simulate RRAM hardware effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure cross-sim for inference\n",
    "config = CrossSimConfig(device_type='RRAM', noise_std=0.05)\n",
    "model_cs = CrossSimModel(model_pt, config)\n",
    "\n",
    "acc_cs = test(model_cs, device, testloader)\n",
    "print(f'PyTorch Training, CrossSim Inference (HW) Test Accuracy: {acc_cs:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Case III: CrossSim Training and Inference (Hardware-Aware Training)\n",
    "\n",
    "Retrain the network using cross-sim to include hardware effects during training (HAT), then evaluate on simulated hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hat = SimpleCNN().to(device)\n",
    "model_hat_cs = CrossSimModel(model_hat, config)\n",
    "optimizer_hat = optim.Adam(model_hat.parameters(), lr=0.001)\n",
    "\n",
    "# Hardware-Aware Training\n",
    "train(model_hat_cs, device, trainloader, optimizer_hat, criterion, epochs=2)\n",
    "acc_hat = test(model_hat_cs, device, testloader)\n",
    "print(f'CrossSim Training & Inference (HAT) Test Accuracy: {acc_hat:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Table\n",
    "\n",
    "| Case | Training | Inference | Test Accuracy (%) |\n",
    "|------|----------|-----------|-------------------|\n",
    "| I    | PyTorch  | PyTorch   | {acc_pt:.2f}      |\n",
    "| II   | PyTorch  | CrossSim  | {acc_cs:.2f}      |\n",
    "| III  | CrossSim | CrossSim  | {acc_hat:.2f}     |\n",
    "\n",
    "Observe how hardware effects degrade accuracy, and how Hardware-Aware Training can help recover it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Draw Your Own Digit!\n",
    "\n",
    "Use the canvas below to draw a digit (0-9). The image will be preprocessed and fed to all three models. See how each model predicts your digit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = Canvas(width=140, height=140, background_color='black')\n",
    "canvas.stroke_style = 'white'\n",
    "canvas.line_width = 12\n",
    "display(canvas)\n",
    "\n",
    "def preprocess_canvas(canvas):\n",
    "    img = np.array(canvas.get_image_data())[..., 0]\n",
    "    img = img / 255.0\n",
    "    img = 1.0 - img  # invert\n",
    "    img = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    img = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "    img = (img - 0.1307) / 0.3081\n",
    "    return img\n",
    "\n",
    "def predict_digit(img):\n",
    "    with torch.no_grad():\n",
    "        img = img.to(device)\n",
    "        out_pt = model_pt(img)\n",
    "        out_cs = model_cs(img)\n",
    "        out_hat = model_hat_cs(img)\n",
    "        pred_pt = out_pt.argmax(dim=1).item()\n",
    "        pred_cs = out_cs.argmax(dim=1).item()\n",
    "        pred_hat = out_hat.argmax(dim=1).item()\n",
    "    return pred_pt, pred_cs, pred_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage after drawing:\n",
    "# img = preprocess_canvas(canvas)\n",
    "# pred_pt, pred_cs, pred_hat = predict_digit(img)\n",
    "# print(f'PyTorch: {pred_pt}, CrossSim: {pred_cs}, HAT: {pred_hat}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cross-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
